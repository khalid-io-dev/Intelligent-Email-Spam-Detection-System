# Spam Detection System - BMSecurity
## SystÃ¨me Intelligent de DÃ©tection de Spams

Une solution complÃ¨te d'analyse et de classification d'emails spam utilisant NLP et Machine Learning.

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Installation](#installation)
3. [Utilisation](#utilisation)
4. [Architecture](#architecture)
5. [RÃ©sultats](#rÃ©sultats)
6. [API Services](#api-services)

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un systÃ¨me de dÃ©tection de spams avec:
- **Analyse de donnÃ©es** complÃ¨te
- **PrÃ©traitement NLP** avancÃ© (tokenization, stemming, stopwords)
- **Vectorisation** TF-IDF
- **ModÃ¨les ML** multiples (Naive Bayes, Logistic Regression, SVM)
- **Services FastAPI** pour dÃ©ploiement en production

## ğŸ“¦ Installation

### DÃ©pendances
```bash
pip install -r requirements.txt
# ou pour API services
pip install -r requirements_api.txt
```

### Fichiers NÃ©cessaires
- `DataSet_Emails.csv` - Dataset d'emails

## ğŸš€ Utilisation

### 1. Analyse ComplÃ¨te (Jupyter Notebook)
```bash
jupyter notebook spam_detection_analysis.ipynb
```

Ce notebook contient:
- Exploration des donnÃ©es
- Analyse de qualitÃ© des donnÃ©es
- Visualisations (WordClouds)
- PrÃ©traitement du texte
- EntraÃ®nement des modÃ¨les
- Comparaison des performances

### 2. Script Standalone
```bash
python spam_detection.py
```

GÃ©nÃ¨re:
- `class_distribution.png` - Distribution spam/ham
- `wordcloud_spam.png` - Mots frÃ©quents spam
- `wordcloud_ham.png` - Mots frÃ©quents ham
- `confusion_matrix_tfidf.png` - Performance du modÃ¨le
- `preprocessed_emails.csv` - Dataset prÃ©processÃ©

### 3. Services FastAPI

#### NLP Service
```bash
uvicorn nlp_service:app --host 0.0.0.0 --port 8001
```

Endpoints:
- `POST /clean` - Nettoie le texte
- `POST /tokenize` - Tokenise le texte
- `POST /stem` - Effectue stemming
- `GET /health` - SantÃ© du service

#### Classification Service
```bash
uvicorn classification_service:app --host 0.0.0.0 --port 8002
```

Endpoints:
- `POST /predict` - PrÃ©dit spam/ham
- `POST /batch-predict` - PrÃ©dictions batch
- `GET /health` - SantÃ© du service
- `GET /info` - Informations du service

## ğŸ—ï¸ Architecture

### Pipeline NLP
```
Email Input
    â†“
Lowercase Normalization
    â†“
Remove Punctuation (regex)
    â†“
Tokenization
    â†“
Remove Stopwords
    â†“
Stemming (Porter)
    â†“
TF-IDF Vectorization
    â†“
ML Classifier
    â†“
Spam/Ham Prediction
```

### ModÃ¨les Disponibles
- **Naive Bayes** - Rapide, baseline
- **Logistic Regression** - Ã‰quilibrÃ©, fiable
- **SVM Linear** - Performance Ã©levÃ©e

## ğŸ“Š RÃ©sultats

### DonnÃ©es Statistiques
- Dataset: ~5000 emails
- Spam/Ham: Distribution analysÃ©e
- Train/Test: 80/20 split

### MÃ©triques de Performance
Les modÃ¨les sont Ã©valuÃ©s sur:
- Accuracy (PrÃ©cision globale)
- Precision (Vrais positifs / Tous positifs)
- Recall (Vrais positifs / Vrais labels)
- F1-Score (Moyenne harmonique)

## ğŸ’¾ Fichiers GÃ©nÃ©rÃ©s

```
ntlk/
â”œâ”€â”€ spam_detection.py              # Script principal
â”œâ”€â”€ spam_detection_analysis.ipynb   # Notebook d'analyse
â”œâ”€â”€ nlp_service.py                 # API NLP
â”œâ”€â”€ classification_service.py       # API Classification
â”œâ”€â”€ requirements.txt               # DÃ©pendances
â”œâ”€â”€ requirements_api.txt           # DÃ©pendances API
â”œâ”€â”€ ARCHITECTURE.md                # Documentation
â”œâ”€â”€ ml_models/                     # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ naive_bayes_model.joblib
â”‚   â”œâ”€â”€ logistic_regression_model.joblib
â”‚   â”œâ”€â”€ svm_model.joblib
â”‚   â”œâ”€â”€ tfidf_vectorizer.joblib
â”‚   â””â”€â”€ model_results.csv
â””â”€â”€ preprocessed_dataset.csv       # Dataset prÃ©processÃ©
```

## ğŸ”§ Configuration

### ParamÃ¨tres TF-IDF
- `max_features`: 3000
- `min_df`: 2
- `max_df`: 0.8

### ParamÃ¨tres ModÃ¨les
- **Logistic Regression**: max_iter=1000
- **SVM**: max_iter=2000
- **Naive Bayes**: Default parameters

